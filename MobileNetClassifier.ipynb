{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee52ccb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from aiy.vision.inference import ModelDescriptor, CameraInference\n",
    "from aiy.vision.models import utils\n",
    "from aiy.vision.streaming.server import StreamingServer\n",
    "from aiy.vision.streaming import svg\n",
    "from aiy.leds import Leds, Color\n",
    "from aiy.board import Board\n",
    "\n",
    "from picamera import PiCamera\n",
    "from IPython.display import Image, display, clear_output\n",
    "\n",
    "import contextlib\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6269c4f0",
   "metadata": {},
   "source": [
    "### MobileNet classifier\n",
    "\n",
    "You can use this notebook to be used with your trained network. The training can be done using this \n",
    "<a href=\"https://colab.research.google.com/github/tproffen/ORCSPiVision/blob/master/Training/aiy_retrain_classification.ipynb\">Colab Notebook</a>.\n",
    "\n",
    "Remember if your joy detector is running, you need to turn it off using the commands `sudo systemctl stop joy_detection_demo.service`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a383051",
   "metadata": {},
   "outputs": [],
   "source": [
    "def svg_overlay(classes, frame_size):\n",
    "\n",
    "    width, height = frame_size\n",
    "    doc = svg.Svg(width=width, height=height)\n",
    "    \n",
    "    for i, c in enumerate(classes):\n",
    "        doc.add(svg.Text(c, x=50, y=(i+1)*50, fill='white', font_size=50))\n",
    "    \n",
    "    return str(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a25227b",
   "metadata": {},
   "source": [
    "These two routines we tool from <a href=\"AIYExamples/vision/mobilenet_based_classifier.py\">mobilenet_based_classifier.py</a> from the example files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e1ce740",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(result, labels, tensor_name, threshold, top_k):\n",
    "    # MobileNet based classification model returns one result vector.\n",
    "\n",
    "    assert len(result.tensors) == 1\n",
    "    tensor = result.tensors[tensor_name]\n",
    "    probs, shape = tensor.data, tensor.shape\n",
    "    assert shape.depth == len(labels)\n",
    "    pairs = [pair for pair in enumerate(probs) if pair[1] > threshold]\n",
    "    pairs = sorted(pairs, key=lambda pair: pair[1], reverse=True)\n",
    "    pairs = pairs[0:top_k]\n",
    "    \n",
    "    return [' %s (%.2f)' % (labels[index], prob) for index, prob in pairs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148e0de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_labels(label_path):\n",
    "    with open(label_path) as label_file:\n",
    "        return [label.strip() for label in label_file.readlines()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b1754ba",
   "metadata": {},
   "source": [
    "### Setting up model\n",
    "\n",
    "This is our own model, so we need to define some things :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d681e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"/home/pi/MyProjects/retrained_graph.binaryproto\"\n",
    "label_path = \"/home/pi/MyProjects/retrained_labels.txt\"\n",
    "\n",
    "model = ModelDescriptor(name='mobilenet_based_classifier',\n",
    "                        input_shape=(1, 160, 160, 3),\n",
    "                        input_normalizer=(128.0, 128.0),\n",
    "                        compute_graph=utils.load_compute_graph(model_path))\n",
    "\n",
    "labels = read_labels(label_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de67ca5",
   "metadata": {},
   "source": [
    "#### Main loop\n",
    "\n",
    "Here is our main loop. To watch the camera feed, you can connect to http://orcspi-vis.local:4664."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f89e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "detection_threshhold = 0.5      # Confidence thresshold to list an object\n",
    "\n",
    "with contextlib.ExitStack() as stack:\n",
    "    leds   = stack.enter_context(Leds())\n",
    "    camera = stack.enter_context(PiCamera(sensor_mode=4, resolution=(820, 616)))\n",
    "    board  = stack.enter_context(Board())\n",
    "\n",
    "    # This starts and runs the streaming of the camera\n",
    "    server = stack.enter_context(StreamingServer(camera))  \n",
    "\n",
    "    print (\"Loading model - hold on ..\")\n",
    "    \n",
    "    # Do inference on VisionBonnet\n",
    "    with CameraInference(model) as inference:\n",
    "        try:   \n",
    "            for result in inference.run():\n",
    "                leds.update(Leds.rgb_on(Color.RED))\n",
    "                processed_results = process(result, labels, \"final_result\",\n",
    "                                           detection_threshhold, 3)\n",
    "                \n",
    "                if(len(processed_results)>0):\n",
    "                    clear_output(wait=True)\n",
    "                    leds.update(Leds.rgb_on(Color.BLUE))\n",
    "                    for result in processed_results:\n",
    "                        print(result)\n",
    "                        \n",
    "                    server.send_overlay(svg_overlay(processed_results, (820, 616)))\n",
    "                                                                                 \n",
    "        except KeyboardInterrupt:\n",
    "            print(\"Interrupted ..\")\n",
    "            \n",
    "    leds.update(Leds.rgb_off())    \n",
    "    print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba369ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd1edd4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
